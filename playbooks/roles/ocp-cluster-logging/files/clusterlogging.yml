---
# Set the default collector type
- set_fact:
    collector_type: "{{ log_collector_type | default('fluentd', true) }}"
    clo_version: "{{ cluster_logging_channel | regex_search('\\d+\\.\\d+') | float }}"
# Check if the ClusterLogging CR is exists
- name: Check if the ClusterLogging instance exists
  shell: oc get ClusterLogging -n openshift-logging | wc -l
  register: check_cl

# Create a OpenShift logging instance
- name: Create an instance for logging operator
  k8s:
    state: present
    definition:
      apiVersion: "logging.openshift.io/v1"
      kind: "ClusterLogging"
      metadata:
        name: "instance"
        namespace: "openshift-logging"
        annotations:
          logging.openshift.io/preview-vector-collector: "{{ (collector_type == 'vector') | ternary('enabled', omit) }}"
      spec:
        managementState: "Managed"
        logStore:
          type: "elasticsearch"
          retentionPolicy:
            application:
              maxAge: 1d
            infra:
              maxAge: 7d
            audit:
              maxAge: 7d
          elasticsearch:
            nodeCount: 3
            storage:
              size: 200G
            resources:
              requests:
                memory: "8Gi"
            proxy:
              resources:
                limits:
                  memory: 256Mi
                requests:
                  memory: 256Mi
            redundancyPolicy: "SingleRedundancy"
        visualization:
          type: "kibana"
          kibana:
            replicas: 1
        curation:
          type: "curator"
          curator:
            schedule: "30 3 * * *"
        collection:
          logs: "{{ collector_spec | from_yaml }}"
  vars:
    collector_spec: |
      type: {{ collector_type }}
      {{ collector_type }}: {}
  register: cl_cr
  when: clo_version | float <= 5.8

- name: Create an instance for logging operator
  k8s:
    state: present
    definition:
      apiVersion: "logging.openshift.io/v1"
      kind: "ClusterLogging"
      metadata:
        name: "instance"
        namespace: "openshift-logging"
        annotations:
          logging.openshift.io/preview-vector-collector: "{{ (collector_type == 'vector') | ternary('enabled', omit) }}"
      spec:
        managementState: "Managed"
        logStore:
          type: "lokistack"
          lokistack:
            name: lokistack-sample
        collection:
          logs: "{{ collector_spec | from_yaml }}"
  vars:
    collector_spec: |
      type: {{ collector_type }}
      {{ collector_type }}: {}
  register: cl_cr
  when: clo_version | float == 5.9

# Create a ConfigMap for lokistack
- name: Create ConfigMap for lokistack
  k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: lokistack-ca
        namespace: openshift-logging
        annotations:
          service.beta.openshift.io/inject-cabundle: "true"
  when: clo_version | float >= 5.9

# Create Service Account
- name: Create Service Account
  shell: |
    oc create sa logcollector -n openshift-logging
    oc adm policy add-cluster-role-to-user collect-application-logs -z logcollector -n openshift-logging
    oc adm policy add-cluster-role-to-user collect-infrastructure-logs -z logcollector -n openshift-logging
    oc adm policy add-cluster-role-to-user collect-audit-logs -z logcollector -n openshift-logging

# Create a Role binding for lokistack
- name: Create Cluster Role for lokistack
  k8s:
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: lokistack-instance-tenant-logs
      rules:
      - apiGroups:
        - 'loki.grafana.com'
        resources:
        - application
        - infrastructure
        - audit
        resourceNames:
        - logs
        verbs:
        - 'get'
        - 'create'
  when: clo_version | float >= 5.9
- name: Create Role binding for lokistack
  k8s:
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: lokistack-instance-tenant-logs
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: lokistack-instance-tenant-logs
      subjects:
      - kind: ServiceAccount
        name: logcollector
        namespace: openshift-logging
  when: clo_version | float >= 5.9		  

# Create lokistack
- name: Create lokistack
  k8s:
    state: present
    definition:
      apiVersion: loki.grafana.com/v1
      kind: LokiStack
      metadata:
        name: lokistack-sample
        namespace: openshift-logging
      spec:
        size: 1x.small
        replicationFactor: 1
        storage:
          secret:
            name: lokicred-secret
            type: s3
        storageClassName: nfs-storage-provisioner
        tenants:
          mode: openshift-logging
        rules:
          enabled: true
          selector:
            matchLabels:
              openshift.io/cluster-monitoring: 'true'
          namespaceSelector:
            matchLabels:
              openshift.io/cluster-monitoring: 'true'
  when: clo_version | float == 5.9

# Create lokistack for 6.0 and above
- name: Create lokistack
  k8s:
    state: present
    definition:
      apiVersion: loki.grafana.com/v1
      kind: LokiStack
      metadata:
        name: lokistack-sample
        namespace: openshift-logging
      spec:
        size: 1x.demo
        replicationFactor: 1
        storage:
          schemas:
          - effectiveDate: "2023-10-15"
            version: v13
          secret:
            name: lokicred-secret
            type: s3
        storageClassName: nfs-storage-provisioner
        tenants:
          mode: openshift-logging
        rules:
          enabled: true
          selector:
            matchLabels:
              openshift.io/cluster-monitoring: 'true'
          namespaceSelector:
            matchLabels:
              openshift.io/cluster-monitoring: 'true'
  when: clo_version | float >= 6.0

# Create a loki log forwarder
- name: Create loki logforwarder
  k8s:
    state: present
    definition:
      apiVersion: logging.openshift.io/v1
      kind: ClusterLogForwarder
      metadata:
        name: instance
        namespace: openshift-logging
      spec:
        pipelines:
          - name: all-to-default
            inputRefs:
            - infrastructure
            - application
            - audit
            outputRefs:
            - default			  
  when: clo_version | float == 5.9

- name: Create loki logforwarder
  k8s:
    state: present
    definition:
      apiVersion: observability.openshift.io/v1
      kind: ClusterLogForwarder
      metadata:
        name: collector
        namespace: openshift-logging
      spec:
        managementState: Managed
        outputs:
          - lokiStack:
              authentication:
                token:
                  from: serviceAccount
              target:
                name: lokistack-sample
                namespace: openshift-logging
            name: lokistack
            tls:
              ca:
                configMapName: lokistack-sample-gateway-ca-bundle
                key: service-ca.crt
            type: lokiStack
        pipelines:
          - inputRefs:
              - infrastructure
              - audit
              - application
            name: forward-to-lokistack
            outputRefs:
              - lokistack
        serviceAccount:
          name: logcollector
  when: clo_version | float >= 6.0
 

- name: Check lokistack secret exists
  shell: oc get secret -n openshift-logging | grep "lokicred-secret" | wc -l
  register: lokisecret
  failed_when: lokisecret.stdout|int == 0
  when: clo_version | float >= 5.9

# Check if deployment is successfull
- name: Check the deployment
  shell: oc get deployment -n openshift-logging | awk '{print $1}' | wc -l
  register: deployments
  until: deployments.stdout|int > 4
  retries: 10
  delay: 120

- name: Check logging pods are restarting if CR for ClusterLogging has changed
  block:
    # Check pods are in restarting state
    - name: Check the logging Pods are restarting
      shell: oc get pods -n openshift-logging --no-headers | awk '{if ($3 == "Terminating" ) print $1}' | wc -l
      register: pods
      until: pods.stdout|int > 0
      retries: 10
      delay: 5
      ignore_errors: yes

    - name: Delete pods if not restarted automatic
      shell: oc delete pod $(oc get pods -n openshift-logging| grep 'fluent\|collector' | awk '{print $1}') -n openshift-logging
      when: pods.failed

    # Check pods are in good state
    - name: Check the logging pods are in good state
      shell: oc get pods -n openshift-logging --no-headers | awk '{if ($3 != "Running" && $3 != "Completed" ) print $1}' | wc -l
      register: pods
      until: pods.stdout|int == 0
      retries: 10
      delay: 90
      ignore_errors: yes
  when: cl_cr.changed and check_cl.stdout|int != 0
  
- name: Get error state pods 
  shell: oc get pod -n openshift-logging | grep Error| wc -l
  register: err_pods

- name: Delete all pods in error state
  shell: oc delete pod $(oc get pods -n openshift-logging| grep Error | awk '{print $1}') -n openshift-logging
  when: err_pods.stdout|int != 0

- name: Check the logging pods are in good state
  shell: oc get pods -n openshift-logging --no-headers | awk '{if ($3 != "Running" && $3 != "Completed" ) print $1}' | wc -l
  register: pods
  until: pods.stdout|int == 0
  retries: 20
  delay: 120
